{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Visualizing Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright Â© Scott Workman. 2024.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _init_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from lmm import LMM\n",
    "from nets import ops\n",
    "from data import DTSDataset\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import argparse\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--method', default='multitask', type=str)\n",
    "parser.add_argument('--loss', default='student', type=str)\n",
    "parser.add_argument('--decoder', default='mlp', type=str)\n",
    "parser.add_argument('--save_dir', default='../logs/', type=str)\n",
    "args = parser.parse_args([])\n",
    "\n",
    "job_dir = \"{}geo_{}_{}_{}\".format(args.save_dir, args.decoder, args.loss,\n",
    "                                  args.method)\n",
    "print(job_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "ckpt_fname = glob.glob(\n",
    "    f\"{job_dir}/lightning_logs/version_0/checkpoints/epoch*.ckpt\")[0]\n",
    "model = LMM.load_from_checkpoint(ckpt_fname, strict=True, **vars(args))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Speed Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dts = DTSDataset('test', dense=True, full=True)\n",
    "\n",
    "dataset = DataLoader(dts, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_sparse(speeds_dense, road_ids):\n",
    "  agg_speed = ops.aggregate(speeds_dense, road_ids)\n",
    "  agg_ids = [int(x) for x in ops.aggregate(road_ids, road_ids)]\n",
    "\n",
    "  # fill road segments with aggregated speed\n",
    "  speeds_sparse = torch.zeros_like(speeds_dense).float()\n",
    "  for speed_, id_ in zip(agg_speed, agg_ids):\n",
    "    mask_segment = road_ids == id_\n",
    "    speeds_sparse[mask_segment] = speed_\n",
    "\n",
    "  return speeds_sparse.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "take = 3\n",
    "\n",
    "for batch_idx, data in zip(range(take), dataset):\n",
    "  print(batch_idx)\n",
    "\n",
    "  inputs, targets = [[y.to(device) for y in x] for x in data]\n",
    "  im = inputs[0]\n",
    "  tar_road, tar_speed, _, _, _, _, tar_road_id = targets\n",
    "\n",
    "  with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "    out_road, out_angle, out_speed = outputs\n",
    "\n",
    "    if args.loss == \"student\":\n",
    "      out_speed = out_speed[:, 0, ...].unsqueeze(1)\n",
    "\n",
    "  out_speed_sparse = make_sparse(out_speed, tar_road_id)\n",
    "\n",
    "  # convert to numpy\n",
    "  t2n = lambda x: x.cpu().squeeze().numpy()\n",
    "  im = t2n(im).transpose(1, 2, 0)\n",
    "  out_speed = t2n(out_speed)\n",
    "  out_speed_sparse = t2n(out_speed_sparse)\n",
    "  tar_speed = t2n(tar_speed)\n",
    "  tar_road = t2n(tar_road)\n",
    "\n",
    "  plt.figure(figsize=(15, 15))\n",
    "  plt.subplot(131)\n",
    "  plt.imshow(im)\n",
    "  tmp = np.ma.masked_where(tar_speed == 0, tar_speed)\n",
    "  plt.imshow(tmp,\n",
    "             cmap=\"RdYlGn\",\n",
    "             vmin=25,\n",
    "             vmax=85,\n",
    "             alpha=.8,\n",
    "             interpolation=\"none\")\n",
    "  plt.title(\"Ground Truth\")\n",
    "  plt.axis(\"off\")\n",
    "\n",
    "  plt.subplot(132)\n",
    "  plt.imshow(im)\n",
    "  tmp = np.ma.masked_where(tar_road == 0, out_speed_sparse)\n",
    "  plt.imshow(tmp,\n",
    "             cmap=\"RdYlGn\",\n",
    "             vmin=25,\n",
    "             vmax=85,\n",
    "             alpha=.8,\n",
    "             interpolation=\"none\")\n",
    "  plt.title(\"Prediction (Aggregated)\")\n",
    "  plt.axis(\"off\")\n",
    "\n",
    "  plt.subplot(133)\n",
    "  plt.imshow(im)\n",
    "  tmp = np.ma.masked_where(tar_road == 0, out_speed)\n",
    "  plt.imshow(tmp,\n",
    "             cmap=\"RdYlGn\",\n",
    "             vmin=25,\n",
    "             vmax=85,\n",
    "             alpha=.8,\n",
    "             interpolation=\"none\")\n",
    "  plt.title(\"Prediction (Dense)\")\n",
    "  plt.axis(\"off\")\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Road Segmentation & Orientation Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dts = DTSDataset('test')\n",
    "\n",
    "dataset = DataLoader(dts, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dense_angles(input_mask, angle_bin_mask, road_id_mask):\n",
    "  valid = angle_bin_mask >= 0\n",
    "  output_mask = np.zeros_like(road_id_mask) - 1\n",
    "\n",
    "  # for each road segment\n",
    "  for idx in range(1, int(np.max(road_id_mask) + 1)):\n",
    "    mask_segment = road_id_mask == idx\n",
    "\n",
    "    # intersect with valid points\n",
    "    mask_points = mask_segment & valid\n",
    "    if np.sum(mask_points) == 0:\n",
    "      continue\n",
    "\n",
    "    # most frequently occuring bin on this segment\n",
    "    angle_max = np.argmax(np.bincount(input_mask[mask_points]))\n",
    "    output_mask[mask_segment] = angle_max\n",
    "\n",
    "  return output_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "take = 3\n",
    "\n",
    "for batch_idx, data in zip(range(take), dataset):\n",
    "  print(batch_idx)\n",
    "\n",
    "  inputs, targets = [[y.to(device) for y in x] for x in data]\n",
    "  im = inputs[0]\n",
    "  tar_road, _, _, tar_angle_bin, _, _, tar_road_id = targets\n",
    "\n",
    "  with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "    out_road, out_angle, _ = outputs\n",
    "    out_road = (out_road > .5)\n",
    "    out_angle_bin = torch.argmax(torch.softmax(out_angle, dim=1), axis=1)\n",
    "\n",
    "  # convert to numpy\n",
    "  t2n = lambda x: x.cpu().squeeze().numpy()\n",
    "  im = t2n(im).transpose(1, 2, 0)\n",
    "  tar_road = t2n(tar_road)\n",
    "  tar_road_id = t2n(tar_road_id)\n",
    "  tar_angle_bin = t2n(tar_angle_bin)\n",
    "  out_road = t2n(out_road)\n",
    "  out_angle_bin = t2n(out_angle_bin)\n",
    "\n",
    "  # get dense angles\n",
    "  tar_angle_dense = get_dense_angles(tar_angle_bin, tar_angle_bin, tar_road_id)\n",
    "  out_angle_dense = get_dense_angles(out_angle_bin, tar_angle_bin, tar_road_id)\n",
    "\n",
    "  plt.figure(figsize=(20, 20))\n",
    "  plt.subplot(151)\n",
    "  plt.imshow(im)\n",
    "  plt.title(\"Image\")\n",
    "  plt.axis(\"off\")\n",
    "\n",
    "  plt.subplot(152)\n",
    "  plt.imshow(tar_road, cmap='gray', vmin=0, vmax=1)\n",
    "  plt.title(\"Road (GT)\")\n",
    "  plt.axis(\"off\")\n",
    "\n",
    "  plt.subplot(153)\n",
    "  plt.imshow(out_road, cmap='gray', vmin=0, vmax=1)\n",
    "  plt.title(\"Road (Pred)\")\n",
    "  plt.axis(\"off\")\n",
    "\n",
    "  plt.subplot(154)\n",
    "  tmp = np.ma.masked_where(tar_road > 0, tar_road)\n",
    "  plt.imshow(tmp, cmap=\"gray\", interpolation=\"none\")\n",
    "  tmp = np.ma.masked_where(tar_angle_dense == -1, tar_angle_dense)\n",
    "  plt.imshow(tmp, cmap=\"hsv\", vmin=0, vmax=15, interpolation=\"none\")\n",
    "  plt.title(\"Orientation (GT)\")\n",
    "  plt.axis(\"off\")\n",
    "\n",
    "  plt.subplot(155)\n",
    "  tmp = np.ma.masked_where(tar_road > 0, tar_road)\n",
    "  plt.imshow(tmp, cmap=\"gray\", interpolation=\"none\")\n",
    "  tmp = np.ma.masked_where(out_angle_dense == -1, out_angle_dense)\n",
    "  plt.imshow(tmp, cmap=\"hsv\", vmin=0, vmax=15, interpolation=\"none\")\n",
    "  plt.title(\"Orientation (Pred)\")\n",
    "  plt.axis(\"off\")\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:image-driven]",
   "language": "python",
   "name": "conda-env-image-driven-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
